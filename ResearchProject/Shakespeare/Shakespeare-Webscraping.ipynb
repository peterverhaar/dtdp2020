{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def PennTreeBank( folgerTag ):\n",
    "    POS = folgerTag\n",
    "    if re.search( r'av\\-c', folgerTag ):\n",
    "        POS = 'RBR'\n",
    "    elif re.search( r'av\\-s', folgerTag ):\n",
    "        POS = 'RBS'\n",
    "    elif re.search( r'av', folgerTag ):\n",
    "        POS = 'RB'\n",
    "        \n",
    "    if re.search( r'j\\-c', folgerTag ):\n",
    "        POS = 'JJR'\n",
    "    elif re.search( r'j\\-s', folgerTag ):\n",
    "        POS = 'JJS'\n",
    "    elif re.search( r'j', folgerTag ):\n",
    "        POS = 'JJ'\n",
    "        \n",
    "    if re.search( r'n1', folgerTag ):\n",
    "        POS = 'NN'\n",
    "    elif re.search( r'n2', folgerTag ):\n",
    "        POS = 'NNS'\n",
    "\n",
    "        \n",
    "    if re.search( r'vvb', folgerTag ):\n",
    "        POS = 'VB'\n",
    "    elif re.search( r'vmb', folgerTag ):\n",
    "        POS = 'MD'\n",
    "    elif re.search( r'vvm', folgerTag ):\n",
    "        POS = 'VBP'\n",
    "    elif re.search( r'vv', folgerTag ):\n",
    "        POS = 'VBD'\n",
    "        \n",
    "    elif re.search( r'crq', folgerTag ):\n",
    "        POS = 'WP'\n",
    "          \n",
    "    if re.search( r'^d', folgerTag ):\n",
    "        POS = 'DT'\n",
    "    \n",
    "    return POS\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "ns = {'t': 'http://www.tei-c.org/ns/1.0'}\n",
    "\n",
    "def readXML( url ):\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    fileName = os.path.basename(url)\n",
    "    fileName_POS = re.sub( '\\.xml$' , '_POS.txt' , fileName )\n",
    "    fileName_lemma = re.sub( '\\.xml$' , '_lemma.txt' , fileName )\n",
    "\n",
    "    pos = open( fileName_POS , 'w' , encoding = 'utf-8' )\n",
    "    lemma = open( fileName_lemma , 'w' , encoding = 'utf-8' )\n",
    "\n",
    "\n",
    "    if response:\n",
    "        root = ET.fromstring(response.text)\n",
    "        #print(root)\n",
    "        sp = root.findall( 't:text//t:sp' , ns)\n",
    "\n",
    "        for e in sp:\n",
    "            \n",
    "            posLine = ''\n",
    "            lemmaLine = ''\n",
    "            w = e.findall( './/t:w' , ns)\n",
    "            for word in w:\n",
    "                #print(w)\n",
    "                #posLine += word.text + ' '\n",
    "                token = word.text\n",
    "                attributes = word.attrib\n",
    "                for a in attributes:\n",
    "                    #print( '@{}: {}'.format( a , attributes[a] ) )\n",
    "                    if a == 'lemma':\n",
    "                        attributes[a] = re.sub( r'[|]' , ' ',  attributes[a] )       \n",
    "                        lemmaLine += attributes[a].lower() + ' '\n",
    "                    if a == 'ana':\n",
    "                        attributes[a] = re.sub( '#' , '' , attributes[a] )\n",
    "                        if re.search( r'[|]', attributes[a]  ):\n",
    "                            parts1 = re.split( r'[|]', token ) \n",
    "                            parts2 = re.split( r'[|]', attributes[a])\n",
    "                            for w in range( len(parts1) ):\n",
    "                                posLine += parts1[w].lower() + '/' + PennTreeBank( parts2[w] ) + ' '\n",
    "                        else:\n",
    "                            posLine += token.lower() + '/' + PennTreeBank( attributes[a] ) + ' '\n",
    "            pos.write( posLine + '\\n' )\n",
    "            lemma.write( lemmaLine + '\\n' )\n",
    "    \n",
    "\n",
    "    pos.close()\n",
    "    lemma.close()\n",
    "    \n",
    "\n",
    "\n",
    "baseUrl = 'https://www.folgerdigitaltexts.org/download/'\n",
    "\n",
    "\n",
    "response = requests.get( baseUrl + 'teisimple.html' )\n",
    "print( response.status_code )\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response.encoding = 'utf-8' \n",
    "    soup = BeautifulSoup( response.text , \"lxml\" )\n",
    "\n",
    "                         \n",
    "    links = soup.find_all(\"a\")\n",
    "                          \n",
    "\n",
    "    for l in links:\n",
    "        linktext = l.string\n",
    "        url = l.get( \"href\")\n",
    "        if re.search( r'xml$' , url ):\n",
    "            print( baseUrl + url)\n",
    "            readXML( baseUrl + url  )\n",
    "else:\n",
    "    print('File could not be downloaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
