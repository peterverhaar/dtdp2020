{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File organisation \n",
    "\n",
    "This is the first of a series of five notebooks that explain how you can perform a number of basic text and data mining operations which will hopefully help you to create useful data for your individual research project in the *Digital Text and Data Processing* course. \n",
    "\n",
    "The code in these notebooks all assume that you have created a working directory on your computer in which you can store all the code for your project. If you have downloaded all the files from the [gitHub resository that was made for this course](https://github.com/peterverhaar/dtdp2020) as a zipped folder, you can use the folder named \"**researchProject**\" for this purpose. This folder already contains the five notebooks that should enable you to carry out the analyses that have been discussed during the course. \n",
    "\n",
    "This folder also contains a folder named '**Corpus**'. In this folder, you should save all the text files that you want to analyse. Plase save all your texts as plain machine-readable TXT files, with all characters encoding using the UTF-8 scheme. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata\n",
    "\n",
    "The technologies associated with Text and Data Mining can be used, among other purposes, to examine the basic syntactic and lexical properties of texts. You can collect data, for instance, about the average number of words per sentence, or about the total number of adjectives. Once you have data about such aspects, you can use such metrics to explore whether the clusters that can be created using formal similarities coincide, in some way or another, with other categorisations, such as those based on genre, historical period, text type or thematic concerns. \n",
    "\n",
    "To be able to explore such correlations, it is necessary, obviously, to have explicit data about the categories that you want to examine. Before you start analysing the texts in your project, it is useful to create a central metadata file, in the CSV format, in which you capture all the categories that you want to study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code that is given in the cell below can be used to create a basic template for the CSV metadata file. As you can see, it creates a file named \"metadata.csv\" on your computer, and it makes a header with two columns: 'title' and 'class'. \n",
    "\n",
    "\n",
    "Next, using the `listdir` method from the `os` module, the code lists all the files in your corpus (i.e. all the TXT files saved in your **Corpus** directory). The program adds these to the metadata file, as values of the 'title' column. Note that the code also removes the '.txt' extension, in an attempt to make the strings look less like a file name, and more like an actual title. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "dir = 'Corpus'\n",
    "\n",
    "md = open( 'metadata.csv' , 'w' , encoding= 'utf-8' )\n",
    "\n",
    "md.write( 'title,class\\n')\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if re.search( 'txt$' , file ):\n",
    "        title = re.sub( r'[.]txt$' , '' , file )\n",
    "        md.write( title + ',\\n' )\n",
    "        \n",
    "md.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importantly, when you only run the code above, the metadata CSV file will still be complete. You still need to add the appropriate values for the 'class' column. This is something which you will neeed to do manually, unless you can develop a method for extracting the data about your categories automatically. If you want to work with more than one categorical variable, you need to edit the header, and, obviously, you also need to supply values for this additional column. \n",
    "\n",
    "The values that you assign at this stage will be used in the other notebooks in this section, to clarify the potential differences between the catagories that are relevant in your study. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dtdpTdm module\n",
    "\n",
    "Many of the analyses that are discussed in the notebooks in this section are based on core data processing or data cleaning operations, such as word tokenisation (i.e. the division of a full text into its individual words) or Part of Speech tagging (i.e. the automated assignment of labels indicating syntactic categories such as nouns or adjectives). As it is inconvenient and inefficient to repeat the full code each time they are needed, the code that you can use for these basic operations have been organised into smaller methods. These methods, moreover, have been saved collectively in a module named '**dtdpTdm**'. Concretely, this module is simply a Python file containing all of these methods. You should make sure that this module is saved in the same folder as the five notebooks in this section. When you want to make use of these methods, you firstly need to import the dtdtTdm module that contain containing them. Optionally, you can also assign an *alias*, a shorter code that you can use to refer to the full name of the module. \n",
    "\n",
    "To learn more about the logic implemented in this module, you can evidently open the dtdpTdm module in a code editor and study the code it contains. If you feel the need to modify the code for some reason, you are free to do this on your own computer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtdpTdm as tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, open the notebook named [Vocabulary.ipynb](Vocabulary.ipynb) to learn how you can systematically analyse the vocabulary of one of the texts in your corpus. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
