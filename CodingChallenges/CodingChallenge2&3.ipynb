{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def tokenise( text ):\n",
    "    tokens = []\n",
    "    text = text.lower()\n",
    "    text = re.sub( '--' , ' -- ' , text)\n",
    "    words = re.split( r'\\s+' , text )\n",
    "    for w in words:\n",
    "        w = w.strip( string.punctuation )\n",
    "        if re.search( r\"[a-zA-Z']\" , w ):\n",
    "            tokens.append(w)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def sortedByValue( dict ):      \n",
    "    return sorted( dict , key=lambda x: dict[x]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Challenge 2\n",
    "\n",
    "Download a random plain text file from Project Gutenberg. Write code to read the text file, and to calculate the type-token ratio of this text.\n",
    "The URL of project Gutenberg is https://www.gutenberg.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "\n",
    "# create variable for the name of the folder containing your texts\n",
    "dir = 'Corpus'\n",
    "\n",
    "# create variable for the name of fil you want to analyse\n",
    "file = 'Ivanhoe.txt'\n",
    "\n",
    "# create a dictionary which will count the tokens\n",
    "# word as index, and frequency as value\n",
    "freq = dict()\n",
    "\n",
    "\n",
    "# read the text, and iterate through the text line by line\n",
    "text = open( join( dir, file ) )\n",
    "\n",
    "# tokenise each line, and update the dictionary as you go along\n",
    "\n",
    "for line in text:\n",
    "    words = tokenise( line )  \n",
    "    for w in words:\n",
    "        freq[w] = freq.get( w, 0 ) + 1\n",
    "\n",
    "nrTokens = 0 \n",
    "        \n",
    "# divide the number of types by the number of tokens\n",
    "for word in reversed( sortedByValue(freq) ):\n",
    "    nrTokens += freq[word]\n",
    "    \n",
    "print(  len(freq) / nrTokens )    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Challenge 3\n",
    "\n",
    "Download the full text of Shakespeare’s Hamlet from the website of Project Gutenberg (Plain Text UTF-8 format).\n",
    "https://www.gutenberg.org/files/1524/1524-0.txt\n",
    "\n",
    "Write an application which can calculate the number of occurrences of the following words: “sleep”, “love”, “hate”, “blood”, “time”, “night”, “father” \n",
    "\n",
    "Also print the 30 most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "import re\n",
    "\n",
    "# create variable for the name of the folder containing your texts\n",
    "dir = 'corpus'\n",
    "\n",
    "# create variable for the name of file you want to analyse\n",
    "file = 'Hamlet.txt'\n",
    "\n",
    "# create a dictionary which will count the tokens\n",
    "# word as index, and frequency as value\n",
    "freq = dict()\n",
    "\n",
    "\n",
    "# read the text\n",
    "text = open( join( dir, file ) )\n",
    "\n",
    "\n",
    "# Read the text, and iterate through the text line by line. \n",
    "# Tokenise each line, and update the dictionary as you go along\n",
    "for line in text:\n",
    "    words = tokenise( line )  \n",
    "    for w in words:\n",
    "        freq[w] = freq.get( w, 0 ) + 1\n",
    "        \n",
    "        \n",
    "print( freq[\"sleep\"] )\n",
    "print( freq[\"love\"] )\n",
    "print( freq[\"hate\"] )\n",
    "print( freq[\"blood\"] )\n",
    "print( freq[\"time\"] )\n",
    "print( freq[\"night\"] )\n",
    "print( freq[\"father\"] )        \n",
    "        \n",
    "count = 0 \n",
    "max = 30        \n",
    "# print the 30 most common words       \n",
    "for word in reversed( sortedByValue(freq) ):\n",
    "    count += 1\n",
    "    print( '{}. {} => {}'.format( count , word , freq[word] ) )\n",
    "    if count == max:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} os\n",
    "!conda install --yes --prefix {sys.prefix} nltk\n",
    "!conda install --yes --prefix {sys.prefix} wordcloud\n",
    "!conda install --yes --prefix {sys.prefix} wordCloud\n",
    "!conda install --yes --prefix {sys.prefix} matplotlib\n",
    "\n",
    "!{sys.executable} -m pip install wordcloud\n",
    "!{sys.executable} -m pip install wordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A word cloud\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nrWords = 200\n",
    "\n",
    "wordcloud = WordCloud( background_color=\"white\",  width=600,height=500, max_words= nrWords ,relative_scaling=1,normalize_plurals=False).generate_from_frequencies( freq )\n",
    "\n",
    "fig = plt.figure( figsize=(10,10) )\n",
    "\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
